<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Flexible Tool for Bias Detection, Visualization, and Mitigation • fairmodels</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="bootstrap-toc.css">
<script src="bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- dalexverse --><link href="dalexverse.css" rel="stylesheet">
<link href="dalexverse-2.css" rel="stylesheet">
<!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="pkgdown.js"></script><meta property="og:title" content="Flexible Tool for Bias Detection, Visualization, and Mitigation">
<meta property="og:description" content="Measure fairness metrics in one place for many models. Check how big is model's bias towards different races, sex, nationalities etc. Use measures such as Statistical Parity, Equal odds to detect the discrimination against unprivileged groups. Visualize the bias using heatmap, radar plot, biplot, bar chart (and more!). There are various pre-processing and post-processing bias mitigation algorithms implemented. Find more details in (Wiśniewski, Biecek (2021)) &lt;arXiv:2104.00507&gt;.  ">
<meta property="og:image" content="/logo.png">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- google analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-5650686-14"></script><script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-5650686-14');
</script>
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-home">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="index.html">fairmodels</a>
        <div class="info">
          <span class="partof">part of the <a href="https://github.com/ModelOriented/DrWhy">DrWhy.AI</a>
           developed by the <a href="https://mi2.mini.pw.edu.pl/">MI^2 DataLab</a> </span>
          <span class="version version-default">1.0.0</span>
        </div>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
<li>
  <a href="reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="articles/Advanced_tutorial.html">Advanced Tutorial</a>
    </li>
    <li>
      <a href="articles/Basic_tutorial.html">Basic Tutorial</a>
    </li>
  </ul>
</li>
<li>
  <a href="news/index.html">Changelog</a>
</li>
        <li>
  <a href="https://github.com/ModelOriented/fairmodels/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="contents col-md-9">
<div id="fairmodels-" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#fairmodels-" class="anchor"></a>fairmodels <img src="reference/figures/logo.png" align="right" width="150">
</h1></div>
<p><!-- badges: start --> <a href="https://codecov.io/gh/ModelOriented/fairmodels?branch=master" class="external-link"><img src="https://codecov.io/gh/ModelOriented/fairmodels/branch/master/graph/badge.svg" alt="Codecov test coverage"></a> <a href="https://github.com/ModelOriented/fairmodels/actions" class="external-link"><img src="https://github.com/ModelOriented/fairmodels/workflows/R-CMD-check/badge.svg" alt="R build status"></a> <a href="https://cran.r-project.org/web/packages/fairmodels/index.html" class="external-link"><img src="https://www.r-pkg.org/badges/version/fairmodels" alt="CRAN"></a> <img src="https://cranlogs.r-pkg.org/badges/fairmodels" alt="Downloads"><a href="http://drwhy.ai/#eXtraAI" class="external-link"><img src="https://img.shields.io/badge/DrWhy-eXtrAI-4378bf" alt="DrWhy-eXtrAI"></a> <!-- badges: end --></p>
<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p>Flexible tool for bias detection, visualization, and mitigation. Uses models explained with <a href="https://modeloriented.github.io/DALEX/" class="external-link">DALEX</a> and calculates fairness metrics based on confusion matrix for protected group. Allows to compare and gain information about various machine learning models. Mitigate bias with various pre-processing and post-processing techniques. <em>Make sure your models are classifying protected groups similarly</em>.</p>
</div>
<div id="preview" class="section level2">
<h2 class="hasAnchor">
<a href="#preview" class="anchor"></a>Preview</h2>
<div class="figure">
<img src="reference/figures/preview.gif" alt=""><p class="caption">preview</p>
</div>
</div>
<div id="installation" class="section level2">
<h2 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h2>
<p>Install it from CRAN:</p>
<pre><code><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages("fairmodels")</a></code></pre>
<p>or developer version from GitHub:</p>
<pre><code>devtools::install_github("ModelOriented/fairmodels")</code></pre>
</div>
<div id="example" class="section level2">
<h2 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h2>
<p>Checking fairness is easy!</p>
<pre><code><a href="https://modeloriented.github.io/fairmodels/" class="external-link">library(fairmodels)
library(ranger)
library(DALEX)

data("german")

# ------------ step 1 - create model(s)  -----------------

lm_model &lt;- glm(Risk~.,
                data = german,
                family=binomial(link="logit"))

rf_model &lt;- ranger(Risk ~.,
                   data = german,
                   probability = TRUE,
                   num.trees = 200)

# ------------  step 2 - create explainer(s)  ------------

# numeric y for explain function
y_numeric &lt;- as.numeric(german$Risk) -1

explainer_lm &lt;- explain(lm_model, data = german[,-1], y = y_numeric)
explainer_rf &lt;- explain(rf_model, data = german[,-1], y = y_numeric)

# ------------  step 3 - fairness check  -----------------

fobject &lt;- fairness_check(explainer_lm, explainer_rf,
                          protected = german$Sex,
                          privileged = "male")

 
print(fobject)
plot(fobject)
</a></code></pre>
<p>Compas recidivism data use case: <a href="https://modeloriented.github.io/fairmodels/articles/Basic_tutorial.html" class="external-link">Basic tutorial</a><br>
Bias mitigation techniques on Adult data: <a href="https://modeloriented.github.io/fairmodels/articles/Advanced_tutorial.html" class="external-link">Advanced tutorial</a></p>
</div>
<div id="how-to-evaluate-fairness" class="section level2">
<h2 class="hasAnchor">
<a href="#how-to-evaluate-fairness" class="anchor"></a>How to evaluate fairness?</h2>
<p align="center">
<img src="reference/figures/flowchart.png" alt="drawing" width="700"></p>
<div id="fairness-checking-is-flexible" class="section level3">
<h3 class="hasAnchor">
<a href="#fairness-checking-is-flexible" class="anchor"></a>Fairness checking is flexible</h3>
<p><code>fairness_check</code> parameters are<br>
* x, … - <code>explainers</code> and <code>fairness_objects</code> (products of fairness_check).<br>
* protected - factor with different subgroups as levels. Usually specific race, sex etc…<br>
* privileged - subgroup, base on which to calculate parity loss metrics.<br>
* cutoff - custom cutoff, might be single value - cutoff same for all subgroups or vector - for each subgroup individually. Affecting only explainers.<br>
* label - character vector for every explainer.</p>
<p>Models might be trained on different data, even without protected variable. May have different cutoffs which gives different values of metrics. <code><a href="reference/fairness_check.html">fairness_check()</a></code> is place where <code>explainers</code> and <code>fairness_objects</code> are checked for compatibility and then glued together.<br>
So it is possible to to something like this:</p>
<pre><code>fairness_object &lt;- fairness_check(explainer1, explainer2, ...)
fairness_object &lt;- fairness_check(explainer3, explainer4, fairness_object, ...)</code></pre>
<p>even with more <code>fairness_objects</code>!</p>
<p>If one is even more keen to know how <code>fairmodels</code> works and what are relations between objects, please look at this diagram <a href="https://github.com/ModelOriented/fairmodels/blob/master/man/figures/class_diagram.png" class="external-link">class diagram</a></p>
</div>
</div>
<div id="metrics-used" class="section level2">
<h2 class="hasAnchor">
<a href="#metrics-used" class="anchor"></a>Metrics used</h2>
<p>There are 12 metrics based on confusion matrix :</p>
<table class="table">
<thead><tr class="header">
<th>Metric</th>
<th>Formula</th>
<th>Full name</th>
<th>fairness names while checking among subgroups</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>TPR</td>
<td><img src="reference/figures/formulas/tpr.jpg" alt="tpr"></td>
<td>true positive rate</td>
<td>equal opportunity</td>
</tr>
<tr class="even">
<td>TNR</td>
<td><img src="reference/figures/formulas/tnr.jpg" alt="tnr"></td>
<td>true negative rate</td>
<td></td>
</tr>
<tr class="odd">
<td>PPV</td>
<td><img src="reference/figures/formulas/ppv.jpg" alt="ppv"></td>
<td>positive predictive value</td>
<td>predictive parity</td>
</tr>
<tr class="even">
<td>NPV</td>
<td><img src="reference/figures/formulas/npv.jpg" alt="npv"></td>
<td>negative predictive value</td>
<td></td>
</tr>
<tr class="odd">
<td>FNR</td>
<td><img src="reference/figures/formulas/fnr.jpg" alt="fnr"></td>
<td>false negative rate</td>
<td></td>
</tr>
<tr class="even">
<td>FPR</td>
<td><img src="reference/figures/formulas/fpr.jpg" alt="fpr"></td>
<td>false positive rate</td>
<td>predictive equality</td>
</tr>
<tr class="odd">
<td>FDR</td>
<td><img src="reference/figures/formulas/fdr.jpg" alt="fdr"></td>
<td>false discovery rate</td>
<td></td>
</tr>
<tr class="even">
<td>FOR</td>
<td><img src="reference/figures/formulas/for.jpg" alt="for"></td>
<td>false omission rate</td>
<td></td>
</tr>
<tr class="odd">
<td>TS</td>
<td><img src="reference/figures/formulas/ts.jpg" alt="ts"></td>
<td>threat score</td>
<td></td>
</tr>
<tr class="even">
<td>STP</td>
<td><img src="reference/figures/formulas/stp.jpg" alt="stp"></td>
<td>statistical parity</td>
<td>statistical parity</td>
</tr>
<tr class="odd">
<td>ACC</td>
<td><img src="reference/figures/formulas/acc.jpg" alt="acc"></td>
<td>accuracy</td>
<td>Overall accuracy equality</td>
</tr>
<tr class="even">
<td>F1</td>
<td><img src="reference/figures/formulas/f1.jpg" alt="f1"></td>
<td>F1 score</td>
<td></td>
</tr>
</tbody>
</table>
<p><em>and their parity loss.</em><br>
How is <em>parity loss</em> calculated?</p>
<div class="figure">
<img src="reference/figures/formulas/parity_loss.png" alt=""><p class="caption">parity_loss</p>
</div>
<p>Where <code>i</code> denotes the membership to unique subgroup from protected variable. Unprivileged subgroups are represented by small letters and privileged by simply “privileged”.</p>
<p>some fairness metrics like <em>Equalized odds</em> are satisfied if parity loss in both <em>TPR</em> and <em>FPR</em> is low</p>
</div>
<div id="related-works" class="section level2">
<h2 class="hasAnchor">
<a href="#related-works" class="anchor"></a>Related works</h2>
<p>Zafar,Valera, Rodriguez, Gummadi (2017) https://arxiv.org/pdf/1610.08452.pdf</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li>Download from CRAN at <br><a href="https://cloud.r-project.org/package=fairmodels">https://​cloud.r-project.org/​package=fairmodels</a>
</li>
<li>Browse source code at <br><a href="https://github.com/ModelOriented/fairmodels/">https://​github.com/​ModelOriented/​fairmodels/​</a>
</li>
<li>Report a bug at <br><a href="https://github.com/ModelOriented/fairmodels/issues">https://​github.com/​ModelOriented/​fairmodels/​issues</a>
</li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html">Citing fairmodels</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Jakub Wiśniewski <br><small class="roles"> Author, maintainer </small>  </li>
<li>Przemysław Biecek <br><small class="roles"> Author </small> <a href="https://orcid.org/0000-0001-8423-1823" target="orcid.widget" aria-label="ORCID"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
</ul>
</div>



  </div>
</div>


      <footer><div class="copyright">
  <p>Developed by Jakub Wiśniewski, Przemysław Biecek.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
