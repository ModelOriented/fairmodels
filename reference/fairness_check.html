<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Fairness check — fairness_check • fairmodels</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- dalexverse --><link href="../dalexverse.css" rel="stylesheet"><link href="../dalexverse-2.css" rel="stylesheet"><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Fairness check — fairness_check"><meta property="og:description" content="Fairness check creates fairness_object which measures different fairness metrics and wraps data, explainers and parameters in useful object. This is fundamental object in this package.
It enables to visualize fairness metrics and models in many ways and compare models on both fairness and performance level. Fairness check acts as merger and wrapper for explainers and fairness objects.
While other fairness objects values are not changed, fairness check assigns cutoffs and labels to provided explainers so same explainers with changed labels/cutoffs might be gradually added to fairness object.
Users through print and plot methods may quickly check values of most popular fairness metrics. More on that topic in details."><meta property="og:image" content="/logo.png"><meta name="robots" content="noindex"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- google analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-5650686-14"></script><script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-5650686-14');
</script></head><body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="../index.html">fairmodels</a>
        <div class="info">
          <span class="partof">part of the <a href="https://github.com/ModelOriented/DrWhy">DrWhy.AI</a>
           developed by the <a href="https://mi2.mini.pw.edu.pl/">MI^2 DataLab</a> </span>
          <span class="version version-default">1.2.0</span>
        </div>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/Advanced_tutorial.html">Advanced Tutorial</a>
    </li>
    <li>
      <a href="../articles/Basic_tutorial.html">Basic Tutorial</a>
    </li>
  </ul></li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
        <li>
  <a href="https://github.com/ModelOriented/fairmodels/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Fairness check</h1>
    <small class="dont-index">Source: <a href="https://github.com/ModelOriented/fairmodels/blob/master/R/fairness_check.R"><code>R/fairness_check.R</code></a></small>
    <div class="hidden name"><code>fairness_check.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Fairness check creates <code>fairness_object</code> which measures different fairness metrics and wraps data, explainers and parameters in useful object. This is fundamental object in this package.
It enables to visualize fairness metrics and models in many ways and compare models on both fairness and performance level. Fairness check acts as merger and wrapper for explainers and fairness objects.
While other fairness objects values are not changed, fairness check assigns cutoffs and labels to provided explainers so same explainers with changed labels/cutoffs might be gradually added to fairness object.
Users through print and plot methods may quickly check values of most popular fairness metrics. More on that topic in details.</p>
    </div>

    <div class="ref-usage sourceCode"><pre class="sourceCode r"><code><span class="fu">fairness_check</span><span class="op">(</span>
  <span class="va">x</span>,
  <span class="va">...</span>,
  protected <span class="op">=</span> <span class="cn">NULL</span>,
  privileged <span class="op">=</span> <span class="cn">NULL</span>,
  cutoff <span class="op">=</span> <span class="cn">NULL</span>,
  label <span class="op">=</span> <span class="cn">NULL</span>,
  epsilon <span class="op">=</span> <span class="fl">0.8</span>,
  verbose <span class="op">=</span> <span class="cn">TRUE</span>,
  colorize <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span></code></pre></div>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments"><colgroup><col class="name"><col class="desc"></colgroup><tr><th>x</th>
      <td><p>object created with <code><a href="https://dalex.drwhy.ai/reference/explain.html">explain</a></code> or of class <code>fairness_object</code>.
It can be multiple fairness_objects, multiple explainers, or combination on both, as long as
they predict the same data. If at least one fairness_object is provided there is no need to
pass protected and privileged parameters. Explainers must be binary classification type.</p></td>
    </tr><tr><th>...</th>
      <td><p>possibly more objects created with <code><a href="https://dalex.drwhy.ai/reference/explain.html">explain</a></code> and/or objects of class <code>fairness_object</code></p></td>
    </tr><tr><th>protected</th>
      <td><p>factor, protected variable (also called sensitive attribute), containing privileged and unprivileged groups</p></td>
    </tr><tr><th>privileged</th>
      <td><p>factor/character, one value of <code>protected</code>, in regard to what subgroup parity loss is calculated</p></td>
    </tr><tr><th>cutoff</th>
      <td><p>numeric, vector of cutoffs (thresholds) for each value of protected variable, affecting only explainers.</p></td>
    </tr><tr><th>label</th>
      <td><p>character, vector of labels to be assigned for explainers, default is explainer label.</p></td>
    </tr><tr><th>epsilon</th>
      <td><p>numeric, boundary for fairness checking, lowest acceptable ratio of metrics between unprivileged and privileged subgroups. Default value is 0.8. More on the idea behind epsilon in details section.</p></td>
    </tr><tr><th>verbose</th>
      <td><p>logical, whether to print information about creation of fairness object</p></td>
    </tr><tr><th>colorize</th>
      <td><p>logical, whether to print information in color</p></td>
    </tr></table><h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>An object of class <code>fairness_object</code> which is a list with elements:</p><ul><li><p>parity_loss_metric_data - data.frame containing parity loss for various fairness metrics. Created with following metrics:</p><ul><li><p>TPR - True Positive Rate (Sensitivity, Recall)</p></li>
<li><p>TNR - True Negative Rate (Specificity)</p></li>
<li><p>PPV - Positive Predictive Value (Precision)</p></li>
<li><p>NPV - Negative Predictive Value</p></li>
<li><p>FNR - False Negative Rate</p></li>
<li><p>FPR - False Positive Rate</p></li>
<li><p>FDR - False Discovery Rate</p></li>
<li><p>FOR - False Omission Rate</p></li>
<li><p>TS - Threat Score</p></li>
<li><p>STP - Statistical Parity</p></li>
<li><p>ACC - Accuracy</p></li>
<li><p>F1 - F1 Score</p></li>
</ul></li>
<li><p>groups_data - metrics across levels in protected variable</p></li>
<li><p>groups_confusion_matrices - confusion matrices for each subgroup</p></li>
<li><p>explainers - list of <code>DALEX</code> explainers used to create object</p></li>
<li><p>cutoffs - list of cutoffs for each explainer and subgroup</p></li>
<li><p>fairness_check_data - <code>data.frame</code> used for for plotting <code>fairness_object</code></p></li>
<li><p>... - other parameters passed to function</p></li>
</ul><h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>Fairness check</p>
<p>Metrics used are made for each subgroup, then base metric score is subtracted leaving loss of particular metric.
If absolute loss of metrics ratio is not within acceptable boundaries than such metric is marked as "not passed". It means that values of metrics should be within (epsilon, 1/epsilon) boundary.
The default ratio is set to 0.8 which adhere to US 80<!-- % rule (more on it here: \url{https://en.wikipedia.org/wiki/Disparate_impact#The_80%_rule}). It means that unprivileged subgroups should have at least 80% -->
score achieved in metrics by privileged subgroup. For example if TPR_unprivileged/TPR_privileged is less than 0.8 then such ratio is sign of discrimination. On the other hand if
TPR_privileged/TPR_unprivileged is more than 1.25 (1/0.8) than there is discrimination towards privileged group.
Epsilon value can be adjusted to user's needs. It should be interpreted as the lowest ratio of metrics allowed.  There are some metrics that might be derived from existing metrics (For example Equalized Odds - equal TPR and FPR for all subgroups).
That means passing 5 metrics in fairness check asserts that model is even more fair. In <code>fairness_check</code> models must always predict positive result. Not adhering to this rule
may lead to misinterpretation of the plot. More on metrics and their equivalents:
<a href="https://fairware.cs.umass.edu/papers/Verma.pdf">https://fairware.cs.umass.edu/papers/Verma.pdf</a>
<a href="https://en.wikipedia.org/wiki/Fairness_(machine_learning)">https://en.wikipedia.org/wiki/Fairness_(machine_learning)</a></p>
<p>Parity loss - visualization tool</p>
<p>Parity loss is computed as follows:
M_parity_loss = sum(abs(log(metric/metric_privileged)))</p>
<p>where:</p>
<p>M - some metric mentioned above</p>
<p>metric - vector of metric scores from each subgroup
metric_privileged - value of metric vector for privileged subgroup</p>
<p>base_metric - scalar, value of metric for base subgroup</p>
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Zafar,Valera, Rodriguez, Gummadi (2017)  <a href="https://arxiv.org/pdf/1610.08452.pdf">https://arxiv.org/pdf/1610.08452.pdf</a></p>
<p>Hardt, Price, Srebro (2016) <a href="https://arxiv.org/pdf/1610.02413.pdf">https://arxiv.org/pdf/1610.02413.pdf</a></p>
<p>Verma, Rubin (2018) <a href="https://fairware.cs.umass.edu/papers/Verma.pdf">https://fairware.cs.umass.edu/papers/Verma.pdf</a></p>
<p>Barocas, Hardt, Narayanan (2019) <a href="https://fairmlbook.org/">https://fairmlbook.org/</a></p>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <div class="ref-examples sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"german"</span><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="va">y_numeric</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">german</span><span class="op">$</span><span class="va">Risk</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="va">lm_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Risk</span> <span class="op">~</span> <span class="va">.</span>,</span>
<span class="r-in">  data <span class="op">=</span> <span class="va">german</span>,</span>
<span class="r-in">  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span class="r-in"><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="va">explainer_lm</span> <span class="op">&lt;-</span> <span class="fu">DALEX</span><span class="fu">::</span><span class="fu"><a href="https://dalex.drwhy.ai/reference/explain.html">explain</a></span><span class="op">(</span><span class="va">lm_model</span>, data <span class="op">=</span> <span class="va">german</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, y <span class="op">=</span> <span class="va">y_numeric</span><span class="op">)</span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Preparation of a new explainer is initiated</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; model label       :  lm  ( <span style="color: #BBBB00;"> default </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; data              :  1000  rows  9  cols </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; target variable   :  1000  values </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; predict function  :  yhat.glm  will be used ( <span style="color: #BBBB00;"> default </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; predicted values  :  No value for predict function target column. ( <span style="color: #BBBB00;"> default </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; model_info        :  package stats , ver. 4.1.1 , task classification ( <span style="color: #BBBB00;"> default </span> ) </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; predicted values  :  numerical, min =  0.1369187 , mean =  0.7 , max =  0.9832426  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; residual function :  difference between y and yhat ( <span style="color: #BBBB00;"> default </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; residuals         :  numerical, min =  -0.9572803 , mean =  1.940006e-17 , max =  0.8283475  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  <span style="color: #00BB00;"> A new explainer has been created! </span> </span>
<span class="r-in"></span>
<span class="r-in"><span class="va">fobject</span> <span class="op">&lt;-</span> <span class="fu">fairness_check</span><span class="op">(</span><span class="va">explainer_lm</span>,</span>
<span class="r-in">  protected <span class="op">=</span> <span class="va">german</span><span class="op">$</span><span class="va">Sex</span>,</span>
<span class="r-in">  privileged <span class="op">=</span> <span class="st">"male"</span></span>
<span class="r-in"><span class="op">)</span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Creating fairness classification object</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Privileged subgroup		: character (<span style="color: #00BB00;"> Ok </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Protected variable		: factor (<span style="color: #00BB00;"> Ok </span> ) </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Cutoff values for explainers	: 0.5 ( for all subgroups ) </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Fairness objects		: 0 objects </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Checking explainers		: 1 in total ( <span style="color: #00BB00;"> compatible </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Metric calculation		: 13/13 metrics calculated for all models</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> <span style="color: #00BB00;"> Fairness object created succesfully </span> </span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fobject</span><span class="op">)</span></span>
<span class="r-plt"><img src="fairness_check-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span class="co"># \donttest{</span></span>
<span class="r-in"><span class="va">rf_model</span> <span class="op">&lt;-</span> <span class="fu">ranger</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ranger/man/ranger.html">ranger</a></span><span class="op">(</span><span class="va">Risk</span> <span class="op">~</span> <span class="va">.</span>,</span>
<span class="r-in">  data <span class="op">=</span> <span class="va">german</span>,</span>
<span class="r-in">  probability <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span class="r-in">  max.depth <span class="op">=</span> <span class="fl">3</span>,</span>
<span class="r-in">  num.trees <span class="op">=</span> <span class="fl">100</span>,</span>
<span class="r-in">  seed <span class="op">=</span> <span class="fl">1</span></span>
<span class="r-in"><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in"></span>
<span class="r-in"><span class="va">explainer_rf</span> <span class="op">&lt;-</span> <span class="fu">DALEX</span><span class="fu">::</span><span class="fu"><a href="https://dalex.drwhy.ai/reference/explain.html">explain</a></span><span class="op">(</span><span class="va">rf_model</span>,</span>
<span class="r-in">  data <span class="op">=</span> <span class="va">german</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>,</span>
<span class="r-in">  y <span class="op">=</span> <span class="va">y_numeric</span></span>
<span class="r-in"><span class="op">)</span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Preparation of a new explainer is initiated</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; model label       :  ranger  ( <span style="color: #BBBB00;"> default </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; data              :  1000  rows  9  cols </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; target variable   :  1000  values </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; predict function  :  yhat.ranger  will be used ( <span style="color: #BBBB00;"> default </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; predicted values  :  No value for predict function target column. ( <span style="color: #BBBB00;"> default </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; model_info        :  package ranger , ver. 0.13.1 , task classification ( <span style="color: #BBBB00;"> default </span> ) </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; predicted values  :  numerical, min =  0.2744313 , mean =  0.6991764 , max =  0.9021086  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; residual function :  difference between y and yhat ( <span style="color: #BBBB00;"> default </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -&gt; residuals         :  numerical, min =  -0.8758052 , mean =  0.0008235875 , max =  0.6119131  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  <span style="color: #00BB00;"> A new explainer has been created! </span> </span>
<span class="r-in"></span>
<span class="r-in"><span class="va">fobject</span> <span class="op">&lt;-</span> <span class="fu">fairness_check</span><span class="op">(</span><span class="va">explainer_rf</span>, <span class="va">fobject</span><span class="op">)</span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Creating fairness classification object</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Privileged subgroup		: character (<span style="color: #BBBB00;"> from first fairness object </span> ) </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Protected variable		: factor (<span style="color: #BBBB00;"> from first fairness object </span> ) </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Cutoff values for explainers	: 0.5 ( for all subgroups ) </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Fairness objects		: 1 object ( <span style="color: #00BB00;"> compatible </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Checking explainers		: 2 in total ( <span style="color: #00BB00;"> compatible </span> )</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -&gt; Metric calculation		: 13/13 metrics calculated for all models</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> <span style="color: #00BB00;"> Fairness object created succesfully </span> </span>
<span class="r-in"></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fobject</span><span class="op">)</span></span>
<span class="r-plt"><img src="fairness_check-2.png" alt="" width="700" height="433"></span>
<span class="r-in"></span>
<span class="r-in"><span class="co"># custom print</span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fobject</span>, fairness_metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ACC"</span>, <span class="st">"TPR"</span><span class="op">)</span><span class="op">)</span></span>
<span class="r-plt"><img src="fairness_check-3.png" alt="" width="700" height="433"></span>
<span class="r-in"><span class="co"># }</span></span>
<span class="r-in"></span>
</code></pre></div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p>Developed by Jakub Wiśniewski, Przemysław Biecek.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer></div>

  


  </body></html>

